{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular text analysis technique is called topic modeling. The ultimate goal of topic modeling is to find various topics that are present in your corpus. Each document in the corpus will be made up of at least one topic, if not multiple topics.\n",
    "\n",
    "In this notebook, we will be covering the steps on how to do **Latent Dirichlet Allocation (LDA)**, which is one of many topic modeling techniques. It was specifically designed for text data.\n",
    "\n",
    "To use a topic modeling technique, you need to provide (1) a document-term matrix and (2) the number of topics you would like the algorithm to pick up.\n",
    "\n",
    "Once the topic modeling technique is applied, your job as a human is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, you can try changing up the number of topics, the terms in the document-term matrix, model parameters, or even try a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #1 (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aah</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbas</th>\n",
       "      <th>abducted</th>\n",
       "      <th>abduction</th>\n",
       "      <th>abdul</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>ziploced</th>\n",
       "      <th>zippedy</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adel_karam</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amy_schumer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beth_stelling</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_jay_oakerson</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chelsea_handler</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chris_rock</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave_chappelle</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>david_cross</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dylan_moran</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george_carlin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iliza_shlesinger</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_hart</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_james</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis_c_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matt_rife</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pete_davidson</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky_gervais</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarah_cooper</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom_segura</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trevor_noah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 10237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aah  ab  abandon  abandoned  abbas  abducted  abduction  \\\n",
       "adel_karam          0   0        0          0      2         0          0   \n",
       "amy_schumer         1   0        0          0      0         0          0   \n",
       "beth_stelling       0   0        0          0      0         0          0   \n",
       "big_jay_oakerson    0   0        0          3      0         0          0   \n",
       "chelsea_handler     0   0        0          0      0         0          0   \n",
       "chris_rock          0   0        0          0      0         0          0   \n",
       "dave_chappelle      1   0        0          0      0         0          0   \n",
       "david_cross         0   0        0          0      0         0          0   \n",
       "dylan_moran         0   1        0          0      0         0          0   \n",
       "george_carlin       0   0        0          0      0         0          0   \n",
       "iliza_shlesinger    0   0        0          0      0         0          0   \n",
       "kevin_hart          3   0        0          0      0         0          0   \n",
       "kevin_james         0   0        0          0      0         0          0   \n",
       "louis_c_k           0   0        0          0      0         0          0   \n",
       "matt_rife           0   0        0          0      0         0          0   \n",
       "pete_davidson       1   0        0          0      0         0          0   \n",
       "ricky_gervais       0   0        1          1      0         1          1   \n",
       "sarah_cooper        0   0        0          1      0         0          0   \n",
       "tom_segura          0   0        0          0      0         0          0   \n",
       "trevor_noah         0   0        0          0      0         0          0   \n",
       "\n",
       "                  abdul  ability  able  ...  ziploced  zippedy  zit  zo  \\\n",
       "adel_karam            0        0     0  ...         0        0    1   0   \n",
       "amy_schumer           0        0     1  ...         0        0    0   0   \n",
       "beth_stelling         0        0     1  ...         0        0    0   0   \n",
       "big_jay_oakerson      0        0     0  ...         0        0    0   0   \n",
       "chelsea_handler       0        1     5  ...         0        0    0   0   \n",
       "chris_rock            0        0     2  ...         0        0    0   0   \n",
       "dave_chappelle        0        0     0  ...         0        0    0   0   \n",
       "david_cross           0        0     6  ...         0        0    0   0   \n",
       "dylan_moran           0        0     4  ...         0        0    0   0   \n",
       "george_carlin         0        0     0  ...         0        0    0   0   \n",
       "iliza_shlesinger      0        0     0  ...         0        0    0   0   \n",
       "kevin_hart            0        0     2  ...         0        0    0   1   \n",
       "kevin_james           0        0     0  ...         0        0    0   0   \n",
       "louis_c_k             0        0     1  ...         0        0    0   0   \n",
       "matt_rife             0        0     3  ...         0        0    0   0   \n",
       "pete_davidson         0        1     1  ...         1        0    0   0   \n",
       "ricky_gervais         1        0     1  ...         0        0    0   0   \n",
       "sarah_cooper          0        0     3  ...         0        0    0   0   \n",
       "tom_segura            0        0     1  ...         0        1    0   0   \n",
       "trevor_noah           0        0     1  ...         0        0    0   0   \n",
       "\n",
       "                  zombie  zombies  zone  zoo  zoologist  zoom  \n",
       "adel_karam             0        0     0    0          0     0  \n",
       "amy_schumer            1        0     0    0          0     0  \n",
       "beth_stelling          0        0     0    0          0     0  \n",
       "big_jay_oakerson       0        0     0    0          0     0  \n",
       "chelsea_handler        0        0     0    0          0     0  \n",
       "chris_rock             0        0     0    1          0     0  \n",
       "dave_chappelle         0        0     0    0          0     0  \n",
       "david_cross            0        0     0    0          0     0  \n",
       "dylan_moran            1        0     1    0          0     0  \n",
       "george_carlin          0        0     0    0          0     0  \n",
       "iliza_shlesinger       1        0     0    0          0     0  \n",
       "kevin_hart             0        1     1    0          0     0  \n",
       "kevin_james            0        0     0    0          0     0  \n",
       "louis_c_k              0        0     0    0          0     0  \n",
       "matt_rife              0        0     1    0          0     0  \n",
       "pete_davidson          0        0     1    0          0     1  \n",
       "ricky_gervais          0        0     0    0          1     0  \n",
       "sarah_cooper           0        0     0    1          0     1  \n",
       "tom_segura             0        0     0    0          0     0  \n",
       "trevor_noah            0        0     0    0          0     0  \n",
       "\n",
       "[20 rows x 10237 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "data = pd.read_pickle('data_dtm_NLP3.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adel_karam</th>\n",
       "      <th>amy_schumer</th>\n",
       "      <th>beth_stelling</th>\n",
       "      <th>big_jay_oakerson</th>\n",
       "      <th>chelsea_handler</th>\n",
       "      <th>chris_rock</th>\n",
       "      <th>dave_chappelle</th>\n",
       "      <th>david_cross</th>\n",
       "      <th>dylan_moran</th>\n",
       "      <th>george_carlin</th>\n",
       "      <th>iliza_shlesinger</th>\n",
       "      <th>kevin_hart</th>\n",
       "      <th>kevin_james</th>\n",
       "      <th>louis_c_k</th>\n",
       "      <th>matt_rife</th>\n",
       "      <th>pete_davidson</th>\n",
       "      <th>ricky_gervais</th>\n",
       "      <th>sarah_cooper</th>\n",
       "      <th>tom_segura</th>\n",
       "      <th>trevor_noah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aah</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbas</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           adel_karam  amy_schumer  beth_stelling  big_jay_oakerson  \\\n",
       "aah                 0            1              0                 0   \n",
       "ab                  0            0              0                 0   \n",
       "abandon             0            0              0                 0   \n",
       "abandoned           0            0              0                 3   \n",
       "abbas               2            0              0                 0   \n",
       "\n",
       "           chelsea_handler  chris_rock  dave_chappelle  david_cross  \\\n",
       "aah                      0           0               1            0   \n",
       "ab                       0           0               0            0   \n",
       "abandon                  0           0               0            0   \n",
       "abandoned                0           0               0            0   \n",
       "abbas                    0           0               0            0   \n",
       "\n",
       "           dylan_moran  george_carlin  iliza_shlesinger  kevin_hart  \\\n",
       "aah                  0              0                 0           3   \n",
       "ab                   1              0                 0           0   \n",
       "abandon              0              0                 0           0   \n",
       "abandoned            0              0                 0           0   \n",
       "abbas                0              0                 0           0   \n",
       "\n",
       "           kevin_james  louis_c_k  matt_rife  pete_davidson  ricky_gervais  \\\n",
       "aah                  0          0          0              1              0   \n",
       "ab                   0          0          0              0              0   \n",
       "abandon              0          0          0              0              1   \n",
       "abandoned            0          0          0              0              1   \n",
       "abbas                0          0          0              0              0   \n",
       "\n",
       "           sarah_cooper  tom_segura  trevor_noah  \n",
       "aah                   0           0            0  \n",
       "ab                    0           0            0  \n",
       "abandon               0           0            0  \n",
       "abandoned             1           0            0  \n",
       "abbas                 0           0            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5970: 'netflix',\n",
       " 1774: 'comedy',\n",
       " 8407: 'specialrecorded',\n",
       " 1364: 'casino',\n",
       " 2757: 'du',\n",
       " 5143: 'liban',\n",
       " 763: 'beirut',\n",
       " 4159: 'hello',\n",
       " 10149: 'wow',\n",
       " 3890: 'great',\n",
       " 3813: 'good',\n",
       " 3038: 'evening',\n",
       " 3794: 'god',\n",
       " 7422: 'rest',\n",
       " 8364: 'soul',\n",
       " 995: 'bored',\n",
       " 1954: 'cool',\n",
       " 10188: 'yeah',\n",
       " 5178: 'like',\n",
       " 10229: 'youve',\n",
       " 442: 'arrived',\n",
       " 6251: 'outer',\n",
       " 8381: 'space',\n",
       " 9846: 'want',\n",
       " 7716: 'say',\n",
       " 9080: 'thank',\n",
       " 9368: 'traveling',\n",
       " 9894: 'way',\n",
       " 7102: 'quite',\n",
       " 2563: 'distance',\n",
       " 1273: 'came',\n",
       " 9176: 'thursday',\n",
       " 10145: 'wouldnt',\n",
       " 5041: 'late',\n",
       " 9662: 'usually',\n",
       " 2635: 'dont',\n",
       " 9366: 'travel',\n",
       " 4491: 'important',\n",
       " 9177: 'thursdaycan',\n",
       " 1769: 'come',\n",
       " 4951: 'kiss',\n",
       " 5399: 'make',\n",
       " 5319: 'love',\n",
       " 261: 'amazing',\n",
       " 5099: 'lebanese',\n",
       " 4877: 'just',\n",
       " 114: 'adore',\n",
       " 4955: 'kissing',\n",
       " 4841: 'jordan',\n",
       " 9938: 'welcome',\n",
       " 7205: 'real',\n",
       " 4723: 'issue',\n",
       " 4843: 'jordanians',\n",
       " 4976: 'know',\n",
       " 9208: 'times',\n",
       " 2457: 'didnt',\n",
       " 9206: 'time',\n",
       " 165: 'ago',\n",
       " 5610: 'met',\n",
       " 3902: 'greet',\n",
       " 8555: 'started',\n",
       " 4910: 'kept',\n",
       " 3802: 'going',\n",
       " 8090: 'sideways',\n",
       " 2689: 'dramatic',\n",
       " 9256: 'tongue',\n",
       " 9297: 'touched',\n",
       " 9262: 'tonsils',\n",
       " 5285: 'looked',\n",
       " 7657: 'said',\n",
       " 9088: 'thats',\n",
       " 2615: 'doing',\n",
       " 9258: 'tonight',\n",
       " 7212: 'really',\n",
       " 8637: 'stop',\n",
       " 4956: 'kissingwho',\n",
       " 544: 'audience',\n",
       " 8885: 'syria',\n",
       " 1864: 'confidence',\n",
       " 3952: 'guests',\n",
       " 897: 'bless',\n",
       " 2018: 'country',\n",
       " 1816: 'competing',\n",
       " 3771: 'glad',\n",
       " 10220: 'youre',\n",
       " 8886: 'syrians',\n",
       " 2467: 'different',\n",
       " 4954: 'kisses',\n",
       " 3034: 'europeans',\n",
       " 6488: 'perfect',\n",
       " 4844: 'jordanianswho',\n",
       " 9106: 'theres',\n",
       " 2126: 'crowd',\n",
       " 15: 'abroad',\n",
       " 2856: 'egypt',\n",
       " 7498: 'right',\n",
       " 5987: 'nice',\n",
       " 2166: 'culture',\n",
       " 4312: 'horny',\n",
       " 6479: 'people',\n",
       " 5687: 'minute',\n",
       " 4802: 'jesus',\n",
       " 7410: 'respect',\n",
       " 5920: 'nationalities',\n",
       " 8784: 'super',\n",
       " 4953: 'kissers',\n",
       " 5564: 'meet',\n",
       " 8554: 'start',\n",
       " 5103: 'left',\n",
       " 5688: 'minutes',\n",
       " 7835: 'sees',\n",
       " 3799: 'goes',\n",
       " 8140: 'situation',\n",
       " 3974: 'guy',\n",
       " 8084: 'sick',\n",
       " 8274: 'sneezes',\n",
       " 4557: 'infects',\n",
       " 4003: 'half',\n",
       " 5100: 'lebanon',\n",
       " 3224: 'farewell',\n",
       " 3976: 'guys',\n",
       " 1207: 'bushy',\n",
       " 721: 'beard',\n",
       " 5974: 'new',\n",
       " 9387: 'trend',\n",
       " 1776: 'comes',\n",
       " 1447: 'chance',\n",
       " 10113: 'wont',\n",
       " 4369: 'hugs',\n",
       " 3274: 'feel',\n",
       " 3642: 'fur',\n",
       " 720: 'bear',\n",
       " 9291: 'totally',\n",
       " 2746: 'drowned',\n",
       " 7964: 'sharp',\n",
       " 8586: 'steel',\n",
       " 2911: 'emery',\n",
       " 939: 'board',\n",
       " 2968: 'enter',\n",
       " 5585: 'mens',\n",
       " 7570: 'room',\n",
       " 4118: 'hear',\n",
       " 3457: 'flush',\n",
       " 2643: 'door',\n",
       " 6195: 'opens',\n",
       " 666: 'barely',\n",
       " 3358: 'finished',\n",
       " 1208: 'business',\n",
       " 7719: 'says',\n",
       " 9125: 'thinking',\n",
       " 4180: 'hes',\n",
       " 10072: 'wipe',\n",
       " 9298: 'touches',\n",
       " 3163: 'face',\n",
       " 10015: 'whos',\n",
       " 802: 'best',\n",
       " 3589: 'friend',\n",
       " 5420: 'man',\n",
       " 10083: 'wish',\n",
       " 5091: 'learn',\n",
       " 10105: 'women',\n",
       " 10215: 'youd',\n",
       " 9123: 'think',\n",
       " 2545: 'disgusted',\n",
       " 4187: 'hi',\n",
       " 8849: 'sweaty',\n",
       " 7135: 'rain',\n",
       " 7592: 'roucha',\n",
       " 997: 'born',\n",
       " 7869: 'sells',\n",
       " 1686: 'clothes',\n",
       " 3984: 'haamra',\n",
       " 8666: 'street',\n",
       " 2819: 'eaten',\n",
       " 3197: 'falafel',\n",
       " 7684: 'sandwich',\n",
       " 4019: 'hand',\n",
       " 1539: 'chilli',\n",
       " 6481: 'pepper',\n",
       " 4252: 'holding',\n",
       " 2725: 'drip',\n",
       " 8542: 'standing',\n",
       " 5849: 'munching',\n",
       " 5822: 'moustache',\n",
       " 2137: 'crumbs',\n",
       " 8906: 'tahini',\n",
       " 7829: 'seeds',\n",
       " 2238: 'dangling',\n",
       " 6051: 'nose',\n",
       " 3996: 'hair',\n",
       " 5284: 'look',\n",
       " 7257: 'red',\n",
       " 9464: 'turnipsbut',\n",
       " 10143: 'worst',\n",
       " 1528: 'chicken',\n",
       " 1065: 'breath',\n",
       " 5686: 'mint',\n",
       " 1675: 'close',\n",
       " 2797: 'ear',\n",
       " 4185: 'hey',\n",
       " 2294: 'dear',\n",
       " 931: 'blows',\n",
       " 8239: 'smell',\n",
       " 3673: 'garlic',\n",
       " 5949: 'need',\n",
       " 8630: 'stomach',\n",
       " 7020: 'pump',\n",
       " 2229: 'damn',\n",
       " 2306: 'decide',\n",
       " 88: 'add',\n",
       " 2272: 'day',\n",
       " 5507: 'mathematically',\n",
       " 7922: 'sex',\n",
       " 5275: 'long',\n",
       " 4171: 'herecome',\n",
       " 8402: 'speaking',\n",
       " 3483: 'food',\n",
       " 6511: 'personal',\n",
       " 6199: 'opinion',\n",
       " 8631: 'stomachs',\n",
       " 3671: 'garbage',\n",
       " 1303: 'cans',\n",
       " 2773: 'dump',\n",
       " 2818: 'eat',\n",
       " 5530: 'mean',\n",
       " 9136: 'thought',\n",
       " 7978: 'sheep',\n",
       " 3203: 'falls',\n",
       " 4034: 'hands',\n",
       " 6738: 'poor',\n",
       " 9121: 'thing',\n",
       " 3739: 'gets',\n",
       " 10142: 'worse',\n",
       " 4716: 'isis',\n",
       " 2516: 'disappear',\n",
       " 849: 'bit',\n",
       " 5096: 'leave',\n",
       " 4100: 'head',\n",
       " 6000: 'nifa',\n",
       " 4690: 'invited',\n",
       " 5529: 'meal',\n",
       " 6137: 'offer',\n",
       " 3152: 'eyeball',\n",
       " 9432: 'try',\n",
       " 8961: 'tasty',\n",
       " 2140: 'crunchy',\n",
       " 4861: 'juicy',\n",
       " 1949: 'cook',\n",
       " 5189: 'lime',\n",
       " 2360: 'delicious',\n",
       " 5232: 'liver',\n",
       " 7714: 'sawda',\n",
       " 4093: 'having',\n",
       " 7188: 'raw',\n",
       " 1059: 'breakfast',\n",
       " 6179: 'onion',\n",
       " 2362: 'deliciouswhat',\n",
       " 4664: 'intestines',\n",
       " 9166: 'throw',\n",
       " 3207: 'familiar',\n",
       " 7706: 'sausages',\n",
       " 8712: 'stuff',\n",
       " 7480: 'rice',\n",
       " 5540: 'meat',\n",
       " 3055: 'ew',\n",
       " 9655: 'used',\n",
       " 8003: 'shit',\n",
       " 4432: 'id',\n",
       " 6156: 'ok',\n",
       " 9864: 'wash',\n",
       " 2669: 'douse',\n",
       " 6905: 'problem',\n",
       " 818: 'big',\n",
       " 2291: 'dealnow',\n",
       " 8960: 'tastier',\n",
       " 7979: 'sheeps',\n",
       " 637: 'balls',\n",
       " 9111: 'theyre',\n",
       " 3250: 'favorite',\n",
       " 3244: 'fatty',\n",
       " 8907: 'tail',\n",
       " 3885: 'grazes',\n",
       " 2820: 'eating',\n",
       " 3900: 'greens',\n",
       " 495: 'asshole',\n",
       " 10216: 'youll',\n",
       " 3926: 'grossed',\n",
       " 9814: 'wait',\n",
       " 6475: 'penis',\n",
       " 3828: 'got',\n",
       " 8743: 'suck',\n",
       " 9087: 'thatll',\n",
       " 10226: 'youthe',\n",
       " 3422: 'fleece',\n",
       " 7613: 'rug',\n",
       " 9869: 'waste',\n",
       " 8972: 'taxi',\n",
       " 2730: 'driver',\n",
       " 4158: 'hell',\n",
       " 10135: 'world',\n",
       " 4141: 'hed',\n",
       " 2251: 'dashboard',\n",
       " 9891: 'wavinghand',\n",
       " 9961: 'whats',\n",
       " 4337: 'hot',\n",
       " 9313: 'toy',\n",
       " 2609: 'dog',\n",
       " 8615: 'stick',\n",
       " 6861: 'press',\n",
       " 1043: 'brakes',\n",
       " 9016: 'tell',\n",
       " 3350: 'fine',\n",
       " 2722: 'drink',\n",
       " 401: 'araak',\n",
       " 4939: 'kills',\n",
       " 5631: 'microbes',\n",
       " 2058: 'crap',\n",
       " 59: 'acid',\n",
       " 1644: 'clear',\n",
       " 3591: 'friends',\n",
       " 8182: 'slaughtered',\n",
       " 509: 'ate',\n",
       " 6590: 'pigged',\n",
       " 8744: 'sucked',\n",
       " 968: 'bones',\n",
       " 5114: 'legs',\n",
       " 1197: 'burst',\n",
       " 8755: 'suffering',\n",
       " 6046: 'normal',\n",
       " 8753: 'suffer',\n",
       " 4945: 'kinds',\n",
       " 3438: 'floating',\n",
       " 4479: 'immediately',\n",
       " 9264: 'took',\n",
       " 2995: 'er',\n",
       " 4329: 'hospitals',\n",
       " 6129: 'odd',\n",
       " 267: 'ambulance',\n",
       " 7191: 'reach',\n",
       " 6189: 'open',\n",
       " 9967: 'wheelchair',\n",
       " 6633: 'pizza',\n",
       " 7204: 'ready',\n",
       " 6269: 'oven',\n",
       " 4463: 'im',\n",
       " 2788: 'dying',\n",
       " 4328: 'hospital',\n",
       " 768: 'believes',\n",
       " 9936: 'weird',\n",
       " 476: 'ask',\n",
       " 10170: 'wrong',\n",
       " 7084: 'question',\n",
       " 4629: 'insurance',\n",
       " 8803: 'sure',\n",
       " 3740: 'getting',\n",
       " 6316: 'paid',\n",
       " 4028: 'handle',\n",
       " 766: 'believe',\n",
       " 10102: 'woman',\n",
       " 9708: 'venomous',\n",
       " 1569: 'choose',\n",
       " 9830: 'walked',\n",
       " 8478: 'sprawled',\n",
       " 1430: 'chair',\n",
       " 6151: 'oh',\n",
       " 3628: 'fun',\n",
       " 2727: 'dripping',\n",
       " 9707: 'venom',\n",
       " 6171: 'onea',\n",
       " 9972: 'wheres',\n",
       " 4: 'abbas',\n",
       " 8675: 'stretcher',\n",
       " 2774: 'dumped',\n",
       " 5009: 'lady',\n",
       " 9433: 'trying',\n",
       " 4599: 'insert',\n",
       " 166: 'agony',\n",
       " 7779: 'screams',\n",
       " 4747: 'jabbing',\n",
       " 5950: 'needed',\n",
       " 4016: 'hammer',\n",
       " 7048: 'push',\n",
       " 4139: 'heck',\n",
       " 2720: 'drilled',\n",
       " 3344: 'finally',\n",
       " 7777: 'screamed',\n",
       " 6317: 'pain',\n",
       " 4401: 'hurt',\n",
       " 3061: 'examined',\n",
       " 1759: 'colonoscopy',\n",
       " 5051: 'laughed',\n",
       " 9947: 'went',\n",
       " 7713: 'saw',\n",
       " 3431: 'flinch',\n",
       " 2023: 'courage',\n",
       " 5356: 'lying',\n",
       " 493: 'asses',\n",
       " 7888: 'sent',\n",
       " 8406: 'specialist',\n",
       " 3116: 'explain',\n",
       " 6907: 'procedure',\n",
       " 4049: 'happening',\n",
       " 4600: 'inside',\n",
       " 2599: 'doctor',\n",
       " 10140: 'worry',\n",
       " 7315: 'relax',\n",
       " 300: 'anesthetic',\n",
       " 5250: 'local',\n",
       " 3707: 'general',\n",
       " 4741: 'ive',\n",
       " 5756: 'money',\n",
       " 9356: 'trap',\n",
       " 8049: 'shouldnt',\n",
       " 2713: 'dressed',\n",
       " 3837: 'gown',\n",
       " 7336: 'remember',\n",
       " 5185: 'likeyou',\n",
       " 9014: 'teletubbies',\n",
       " 9905: 'wear',\n",
       " 3625: 'fullon',\n",
       " 6177: 'onesie',\n",
       " 1216: 'butopen',\n",
       " 486: 'ass',\n",
       " 185: 'aim',\n",
       " 5286: 'looking',\n",
       " 6094: 'nurses',\n",
       " 5052: 'laughing',\n",
       " 7510: 'ringing',\n",
       " 5050: 'laugh',\n",
       " 8704: 'stuck',\n",
       " 1758: 'colonoscope',\n",
       " 5063: 'lay',\n",
       " 1492: 'check',\n",
       " 9332: 'trainees',\n",
       " 8915: 'taking',\n",
       " 6058: 'notes',\n",
       " 2494: 'dip',\n",
       " 9689: 'vaseline',\n",
       " 3118: 'explaining',\n",
       " 64: 'acolonoscope',\n",
       " 2497: 'dips',\n",
       " 8560: 'starts',\n",
       " 6702: 'poke',\n",
       " 3467: 'focusing',\n",
       " 5699: 'miss',\n",
       " 3187: 'fail',\n",
       " 6704: 'poking',\n",
       " 9204: 'till',\n",
       " 3284: 'felt',\n",
       " 8714: 'stuffing',\n",
       " 8706: 'student',\n",
       " 7634: 'rushing',\n",
       " 8358: 'sorry',\n",
       " 6925: 'professor',\n",
       " 9324: 'traffic',\n",
       " 9050: 'terrible',\n",
       " 10139: 'worries',\n",
       " 9430: 'truth',\n",
       " 4941: 'kind',\n",
       " 5179: 'liked',\n",
       " 8405: 'special',\n",
       " 3542: 'fourth',\n",
       " 3611: 'fuck',\n",
       " 3812: 'gonna',\n",
       " 5186: 'liking',\n",
       " 1904: 'considered',\n",
       " 5407: 'making',\n",
       " 8802: 'supposed',\n",
       " 8109: 'simple',\n",
       " 7014: 'pulling',\n",
       " 8153: 'size',\n",
       " 5836: 'mr',\n",
       " 4889: 'karam',\n",
       " 8422: 'spend',\n",
       " 6004: 'night',\n",
       " 2034: 'covers',\n",
       " 7814: 'second',\n",
       " 1634: 'class',\n",
       " 5536: 'meant',\n",
       " 9140: 'thoughtsecond',\n",
       " 1488: 'cheaper',\n",
       " 9466: 'turns',\n",
       " 2465: 'difference',\n",
       " 8645: 'story',\n",
       " 396: 'appropriate',\n",
       " 3444: 'floor',\n",
       " 8139: 'sitting',\n",
       " 6896: 'privacy',\n",
       " 7815: 'secondclass',\n",
       " 4969: 'knew',\n",
       " 7597: 'round',\n",
       " 7606: 'rubber',\n",
       " 8136: 'sit',\n",
       " 6397: 'passing',\n",
       " 8713: 'stuffed',\n",
       " 6088: 'number',\n",
       " 789: 'bengali',\n",
       " 6217: 'orderly',\n",
       " 8128: 'sir',\n",
       " 7574: 'rooms',\n",
       " 738: 'beds',\n",
       " 6158: 'old',\n",
       " 9744: 'view',\n",
       " 1408: 'cemetery',\n",
       " 7500: 'righthandside',\n",
       " 734: 'bed',\n",
       " 9834: 'wall',\n",
       " 7642: 'sack',\n",
       " 6785: 'potatoes',\n",
       " 4038: 'hang',\n",
       " 9024: 'temperature',\n",
       " 2872: 'elderly',\n",
       " 10193: 'years',\n",
       " 10028: 'wife',\n",
       " 10: 'abo',\n",
       " 2239: 'dani',\n",
       " 2896: 'em',\n",
       " 4456: 'ill',\n",
       " 1466: 'charge',\n",
       " 5898: 'names',\n",
       " 2932: 'enaam',\n",
       " 180: 'aida',\n",
       " 900: 'blew',\n",
       " 5670: 'mind',\n",
       " 332: 'answer',\n",
       " 8411: 'specifically',\n",
       " 2933: 'enaams',\n",
       " 181: 'aidas',\n",
       " 7904: 'served',\n",
       " 4057: 'hard',\n",
       " 4999: 'labor',\n",
       " 6893: 'prison',\n",
       " 6366: 'pardoned',\n",
       " 864: 'black',\n",
       " 2102: 'crinkly',\n",
       " 3153: 'eyebrows',\n",
       " 4738: 'ittybitty',\n",
       " 3157: 'eyes',\n",
       " 8087: 'sideburns',\n",
       " 7627: 'running',\n",
       " 5823: 'mouth',\n",
       " 886: 'bleached',\n",
       " 1760: 'color',\n",
       " 8037: 'short',\n",
       " 8166: 'skinny',\n",
       " 9994: 'white',\n",
       " 3651: 'fuzz',\n",
       " 4084: 'hates',\n",
       " 5583: 'men',\n",
       " 6696: 'point',\n",
       " 10023: 'wide',\n",
       " 9107: 'thermometer',\n",
       " 8573: 'stay',\n",
       " 7058: 'puts',\n",
       " 8208: 'slips',\n",
       " 4830: 'joining',\n",
       " 8346: 'son',\n",
       " 1649: 'clench',\n",
       " 10125: 'work',\n",
       " 1650: 'clenching',\n",
       " 10129: 'working',\n",
       " 1541: 'chimes',\n",
       " 10150: 'wrap',\n",
       " 3689: 'gauze',\n",
       " 9115: 'thicken',\n",
       " 1678: 'closer',\n",
       " 10242: 'zit',\n",
       " 5415: 'mallow',\n",
       " 4733: 'itll',\n",
       " 5305: 'lot',\n",
       " 520: 'attached',\n",
       " 2455: 'did',\n",
       " 2970: 'entering',\n",
       " 2243: 'danis',\n",
       " 4265: 'home',\n",
       " 5499: 'mat',\n",
       " 6065: 'noticed',\n",
       " 7982: 'shelf',\n",
       " 9471: 'tv',\n",
       " 1537: 'childrens',\n",
       " 6579: 'pictures',\n",
       " 1532: 'child',\n",
       " 6159: 'older',\n",
       " 3237: 'fat',\n",
       " 6578: 'picture',\n",
       " 2241: 'danielle',\n",
       " 2871: 'elder',\n",
       " 2259: 'daughter',\n",
       " 5473: 'married',\n",
       " 5235: 'living',\n",
       " 1285: 'canada',\n",
       " 6582: 'piece',\n",
       " 2123: 'crotchet',\n",
       " 3240: 'father',\n",
       " 449: 'art',\n",
       " 4133: 'heaven',\n",
       " 7718: 'saying',\n",
       " 1969: 'corner',\n",
       " 8072: 'shrine',\n",
       " 9760: 'virgin',\n",
       " 5481: 'mary',\n",
       " 1299: 'candles',\n",
       " 1472: 'charity',\n",
       " 1020: 'box',\n",
       " 7427: 'restoration',\n",
       " 5445: 'mar',\n",
       " 7942: 'shalita',\n",
       " 1597: 'church',\n",
       " 2601: 'doctors',\n",
       " 4493: 'impossible',\n",
       " 4259: 'holler',\n",
       " 9247: 'told',\n",
       " 6771: 'possible',\n",
       " 9639: 'upgrade',\n",
       " 7877: 'send',\n",
       " 8809: 'surgeon',\n",
       " 7867: 'sell',\n",
       " 4931: 'kidney',\n",
       " 3949: 'guess',\n",
       " 3106: 'expensive',\n",
       " 1450: 'change',\n",
       " 5826: 'moved',\n",
       " 2217: 'cynthia',\n",
       " 4789: 'jennifer',\n",
       " 3031: 'euphoric',\n",
       " 4768: 'jasmine',\n",
       " 5130: 'let',\n",
       " 282: 'anabella',\n",
       " 8925: 'tall',\n",
       " 729: 'beautiful',\n",
       " 7931: 'sexy',\n",
       " 3824: 'gorgeous',\n",
       " 5230: 'live',\n",
       " 9234: 'toast',\n",
       " 7099: 'quinoa',\n",
       " 5321: 'lovely',\n",
       " 4292: 'hook',\n",
       " 8603: 'stepped',\n",
       " 8236: 'smashed',\n",
       " 4293: 'hooked',\n",
       " 792: 'bent',\n",
       " 3386: 'fivestar',\n",
       " 9378: 'treatment',\n",
       " 7230: 'received',\n",
       " 5846: 'multilingual',\n",
       " 972: 'bonsoir',\n",
       " 5765: 'monsieur',\n",
       " 8384: 'spacious',\n",
       " 9840: 'walls',\n",
       " 3897: 'green',\n",
       " 4949: 'kingsize',\n",
       " 5102: 'ledscreen',\n",
       " 9472: 'tvcurved',\n",
       " 7345: 'remote',\n",
       " 1935: 'control',\n",
       " 1442: 'champ',\n",
       " 9295: 'touch',\n",
       " 4736: 'itstop',\n",
       " 6926: 'professors',\n",
       " 8571: 'status',\n",
       " 481: 'asleep',\n",
       " 8285: 'snoozing',\n",
       " 9300: 'touching',\n",
       " 9824: 'wake',\n",
       " 199: 'ajeeaa',\n",
       " 1805: 'company',\n",
       " 5424: 'manager',\n",
       " 7661: 'saints',\n",
       " 9878: 'watching',\n",
       " 1952: 'cooking',\n",
       " 8066: 'shows',\n",
       " 5840: 'mtv',\n",
       " 9539: 'unbelievable',\n",
       " 477: 'asked',\n",
       " 9238: 'today',\n",
       " 2760: 'duck',\n",
       " 1383: 'cauliflower',\n",
       " 7124: 'radish',\n",
       " 2417: 'dessert',\n",
       " 7006: 'puff',\n",
       " 6411: 'pastry',\n",
       " 7178: 'raspberry',\n",
       " 1521: 'cherry',\n",
       " 7260: 'reduction',\n",
       " 41: 'accompanied',\n",
       " 9759: 'violinist',\n",
       " 9660: 'using',\n",
       " 3515: 'fork',\n",
       " 4971: 'knife',\n",
       " 1194: 'burp',\n",
       " 5770: 'months',\n",
       " 5043: 'later',\n",
       " 9770: 'visit',\n",
       " 4115: 'health',\n",
       " 6906: 'problems',\n",
       " 7210: 'realized',\n",
       " 2307: 'decided',\n",
       " 9331: 'trainee',\n",
       " 3958: 'guinea',\n",
       " 6588: 'pig',\n",
       " 3112: 'experimenting',\n",
       " 3144: 'extras',\n",
       " 89: 'added',\n",
       " 9122: 'things',\n",
       " 3989: 'hadnt',\n",
       " 7833: 'seen',\n",
       " 4615: 'installed',\n",
       " 770: 'bell',\n",
       " 2837: 'edmond',\n",
       " 5568: 'megaes',\n",
       " 1032: 'brackets',\n",
       " 4119: 'heard',\n",
       " 9984: 'whirring',\n",
       " 8369: 'sound',\n",
       " 7155: 'rang',\n",
       " 771: 'bellbirds',\n",
       " 1555: 'chirruping',\n",
       " 4973: 'knocked',\n",
       " 6190: 'opened',\n",
       " 9668: 'vacuuming',\n",
       " 7975: 'shed',\n",
       " 1114: 'brought',\n",
       " 10070: 'winter',\n",
       " 5012: 'laid',\n",
       " 1588: 'christmas',\n",
       " 9381: 'tree',\n",
       " 4302: 'hope',\n",
       " 3275: 'feeling',\n",
       " 808: 'better',\n",
       " 9084: 'thanks',\n",
       " 10208: 'yesterdays',\n",
       " 3509: 'forget',\n",
       " 9405: 'trip',\n",
       " 143: 'africa',\n",
       " 3107: 'experience',\n",
       " 9771: 'visited',\n",
       " 4433: 'idea',\n",
       " 216: 'ali',\n",
       " 8051: 'shour',\n",
       " 970: 'bonjour',\n",
       " 248: 'aloush',\n",
       " 4743: 'ivory',\n",
       " 1705: 'coast',\n",
       " 7533: 'roads',\n",
       " 5199: 'lined',\n",
       " 642: 'banana',\n",
       " 9382: 'trees',\n",
       " 1317: 'car',\n",
       " 8923: 'talking',\n",
       " 593: 'bachelor',\n",
       " 8920: 'talk',\n",
       " 144: 'african',\n",
       " 5924: 'naturally',\n",
       " 1155: 'built',\n",
       " 6652: 'plastic',\n",
       " 8810: 'surgery',\n",
       " 1262: 'calling',\n",
       " 8841: 'swear',\n",
       " 4047: 'happened',\n",
       " 7528: 'river',\n",
       " 692: 'bathing',\n",
       " 3773: 'glance',\n",
       " 8552: 'staring',\n",
       " 4088: 'hauled',\n",
       " 7791: 'scrubbing',\n",
       " 6572: 'picked',\n",
       " 5081: 'leaf',\n",
       " 3841: 'grabbing',\n",
       " 8868: 'switch',\n",
       " 9879: 'water',\n",
       " 8075: 'shrunk',\n",
       " 1289: 'cancel',\n",
       " 1258: 'called',\n",
       " 610: 'bad',\n",
       " 4468: 'imagine',\n",
       " 4339: 'hotel',\n",
       " 8684: 'strip',\n",
       " 7983: 'shell',\n",
       " 7986: 'shes',\n",
       " 4005: 'halfmeter',\n",
       " 1414: 'centimeters',\n",
       " 6325: 'pair',\n",
       " 9480: 'tweezers',\n",
       " 7011: 'pull',\n",
       " 4381: 'humiliated',\n",
       " 251: 'alright',\n",
       " 9186: 'tickle',\n",
       " 8155: 'sizes',\n",
       " 9365: 'traumatized',\n",
       " 616: 'bag',\n",
       " 6623: 'pistachios',\n",
       " 1005: 'bottle',\n",
       " 3326: 'figure',\n",
       " 1778: 'comfortable',\n",
       " 6225: 'organs',\n",
       " 1410: 'censored',\n",
       " 3277: 'feels',\n",
       " 9982: 'whips',\n",
       " 2394: 'depressed',\n",
       " 630: 'balcony',\n",
       " 8247: 'smoke',\n",
       " 9831: 'walking',\n",
       " 7348: 'removing',\n",
       " 6451: 'pee',\n",
       " 9635: 'unzipped',\n",
       " 6349: 'pants',\n",
       " 7563: 'rolling',\n",
       " 7581: 'rope',\n",
       " 9277: 'topless',\n",
       " 6392: 'pass',\n",
       " 6452: 'peeing',\n",
       " 4469: 'imagined',\n",
       " 3839: 'grab',\n",
       " 2941: 'end',\n",
       " 1544: 'china',\n",
       " 7543: 'rocco',\n",
       " 8705: 'stud',\n",
       " 6754: 'porn',\n",
       " 8546: 'star',\n",
       " 938: 'blushed',\n",
       " 4980: 'knows',\n",
       " 8568: 'statistics',\n",
       " 402: 'arabs',\n",
       " 7158: 'rank',\n",
       " 8137: 'sites',\n",
       " 7903: 'seriously',\n",
       " 108: 'admit',\n",
       " 2607: 'doesnt',\n",
       " 9874: 'watch',\n",
       " 2546: 'disgusting',\n",
       " 1081: 'bride',\n",
       " 3920: 'groom',\n",
       " 5591: 'mention',\n",
       " 9580: 'undressing',\n",
       " 4192: 'high',\n",
       " 4145: 'heels',\n",
       " 5201: 'lingerie',\n",
       " 8750: 'suddenly',\n",
       " 8438: 'spilling',\n",
       " 7943: 'shall',\n",
       " 590: 'baby',\n",
       " 2795: 'eagle',\n",
       " 6765: 'position',\n",
       " 1663: 'climb',\n",
       " 1680: 'closet',\n",
       " 4868: 'jump',\n",
       " 3400: 'flap',\n",
       " 3982: 'gyrate',\n",
       " 8018: 'shocked',\n",
       " 5132: 'lets',\n",
       " 1449: 'chandelier',\n",
       " 9492: 'twirl',\n",
       " 4435: 'ideas',\n",
       " 9866: 'washing',\n",
       " 5364: 'machine',\n",
       " 8539: 'stand',\n",
       " 2606: 'does',\n",
       " 9875: 'watched',\n",
       " 5830: 'movie',\n",
       " 3831: 'gotten',\n",
       " 3222: 'far',\n",
       " 5520: 'maximum',\n",
       " 4050: 'happens',\n",
       " 5080: 'leading',\n",
       " 2458: 'die',\n",
       " 3357: 'finish',\n",
       " 5831: 'movies',\n",
       " 2366: 'delivery',\n",
       " 69: 'acting',\n",
       " 10126: 'worked',\n",
       " 6636: 'place',\n",
       " 3151: 'eye',\n",
       " 5960: 'neighbor',\n",
       " 9818: 'waiting',\n",
       " 6215: 'order',\n",
       " 9906: 'wearing',\n",
       " 9565: 'underneath',\n",
       " 8205: 'slip',\n",
       " 70: 'action',\n",
       " 6758: 'pornstar',\n",
       " 5829: 'moves',\n",
       " 4924: 'kicked',\n",
       " 8080: 'shut',\n",
       " 6733: 'pool',\n",
       " 2208: 'cute',\n",
       " 1642: 'cleaning',\n",
       " 3436: 'flirting',\n",
       " 6680: 'plumber',\n",
       " 9907: 'wears',\n",
       " 6271: 'overalls',\n",
       " 1264: 'calls',\n",
       " 443: 'arrives',\n",
       " 574: 'away',\n",
       " 950: 'body',\n",
       " 9578: 'undoes',\n",
       " 5894: 'naked',\n",
       " 6681: 'plumbers',\n",
       " 775: 'belly',\n",
       " 785: 'bends',\n",
       " 4349: 'house',\n",
       " 3387: 'fix',\n",
       " 8938: 'tap',\n",
       " 1217: 'butt',\n",
       " 1502: 'cheeks',\n",
       " 5138: 'levels',\n",
       " 6037: 'nonred',\n",
       " 4000: 'hairy',\n",
       " 4194: 'higher',\n",
       " 5136: 'level',\n",
       " 1785: 'coming',\n",
       " 784: 'bending',\n",
       " 5535: 'means',\n",
       " 128: 'advice',\n",
       " 10106: 'womens',\n",
       " 9037: 'tennis',\n",
       " 5500: 'match',\n",
       " 8400: 'speak',\n",
       " 3738: 'geta',\n",
       " 8015: 'shiver',\n",
       " 1440: 'challenging',\n",
       " 8171: 'skirts',\n",
       " 9120: 'thighs',\n",
       " 4253: 'holds',\n",
       " 7117: 'racket',\n",
       " 6843: 'prepare',\n",
       " 9310: 'towel',\n",
       " 9988: 'whisky',\n",
       " 9221: 'tissue',\n",
       " 6355: 'paper',\n",
       " 9360: 'trash',\n",
       " 836: 'bin',\n",
       " 6844: 'prepared',\n",
       " 2505: 'director',\n",
       " 8913: 'takes',\n",
       " 1683: 'closeups',\n",
       " 8842: 'sweat',\n",
       " 6660: 'player',\n",
       " 8044: 'shot',\n",
       " 8170: 'skirt',\n",
       " 8511: 'stacked',\n",
       " 7264: 'referee',\n",
       " 7094: 'quiet',\n",
       " 9849: 'wants',\n",
       " 8101: 'silence',\n",
       " 2717: 'dribbles',\n",
       " 633: 'ball',\n",
       " 7910: 'set',\n",
       " 3495: 'forbid',\n",
       " 4080: 'hate',\n",
       " 5472: 'marriage',\n",
       " 3247: 'fault',\n",
       " 6275: 'overdramatic',\n",
       " 9919: 'weddings',\n",
       " 381: 'applaud',\n",
       " 2021: 'couple',\n",
       " 7783: 'screw',\n",
       " 8010: 'shittiest',\n",
       " 6121: 'occasion',\n",
       " 1629: 'clapping',\n",
       " 9712: 'venue',\n",
       " 8523: 'staircase',\n",
       " 9917: 'wedding',\n",
       " 6913: 'procession',\n",
       " 3138: 'extra',\n",
       " 7294: 'regular',\n",
       " 1996: 'costumed',\n",
       " 6494: 'performers',\n",
       " 4233: 'history',\n",
       " 7664: 'saladins',\n",
       " 2274: 'days',\n",
       " 1349: 'carrying',\n",
       " 4858: 'jugs',\n",
       " 8862: 'swinging',\n",
       " 8874: 'swords',\n",
       " 9243: 'toilet',\n",
       " 1327: 'careful',\n",
       " 8194: 'slice',\n",
       " 5311: 'loud',\n",
       " 6388: 'party',\n",
       " 8543: 'stands',\n",
       " 5633: 'microphone',\n",
       " 8524: 'stairs',\n",
       " 376: 'appear',\n",
       " 5338: 'luckily',\n",
       " 8053: 'shouting',\n",
       " 7808: 'seat',\n",
       " 1345: 'carried',\n",
       " 8138: 'sits',\n",
       " 1348: 'carry',\n",
       " 575: 'awed',\n",
       " 7454: 'reveal',\n",
       " 3698: 'gazelle',\n",
       " 5775: 'moon',\n",
       " 378: 'appeared',\n",
       " 9953: 'wet',\n",
       " 10087: 'witch',\n",
       " 1109: 'broom',\n",
       " 731: 'beauty',\n",
       " 1808: 'compared',\n",
       " 4440: 'idiot',\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10250"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10237"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_counts.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term), we need to specify two other parameters - the number of topics and the number of passes. Let's start the number of topics at 2, see if the results make sense, and increase the number from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"saddle\" + 0.006*\"gone\" + 0.006*\"offputting\" + 0.006*\"mall\" + 0.006*\"theyve\" + 0.006*\"wallbuilder\" + 0.006*\"shin\" + 0.006*\"therapist\" + 0.005*\"gonna\" + 0.005*\"herring\"'),\n",
       " (1,\n",
       "  '0.006*\"saddle\" + 0.006*\"goin\" + 0.006*\"wallbuilder\" + 0.005*\"theyve\" + 0.005*\"herring\" + 0.005*\"offputting\" + 0.005*\"gonna\" + 0.004*\"therapist\" + 0.004*\"longevity\" + 0.004*\"cause\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"theyve\" + 0.007*\"offputting\" + 0.006*\"saddle\" + 0.006*\"herring\" + 0.006*\"therapist\" + 0.005*\"gone\" + 0.005*\"wallbuilder\" + 0.005*\"goin\" + 0.004*\"ittybitty\" + 0.004*\"did\"'),\n",
       " (1,\n",
       "  '0.007*\"theyve\" + 0.007*\"wallbuilder\" + 0.007*\"godspeed\" + 0.006*\"gonna\" + 0.006*\"goin\" + 0.006*\"offputting\" + 0.006*\"saddle\" + 0.006*\"fuckin\" + 0.005*\"herring\" + 0.005*\"fubu\"'),\n",
       " (2,\n",
       "  '0.007*\"mall\" + 0.007*\"saddle\" + 0.007*\"shin\" + 0.006*\"gone\" + 0.006*\"gonna\" + 0.005*\"goin\" + 0.005*\"cause\" + 0.005*\"wallbuilder\" + 0.005*\"offputting\" + 0.005*\"savage\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"offputting\" + 0.005*\"godspeed\" + 0.005*\"theyve\" + 0.005*\"gonna\" + 0.005*\"herring\" + 0.004*\"goin\" + 0.004*\"doing\" + 0.004*\"sandler\" + 0.004*\"gone\" + 0.004*\"cause\"'),\n",
       " (1,\n",
       "  '0.007*\"theyve\" + 0.007*\"offputting\" + 0.006*\"therapist\" + 0.006*\"wallbuilder\" + 0.006*\"gone\" + 0.006*\"goin\" + 0.005*\"herring\" + 0.005*\"gonna\" + 0.005*\"savage\" + 0.005*\"shin\"'),\n",
       " (2,\n",
       "  '0.009*\"mall\" + 0.007*\"saddle\" + 0.007*\"wallbuilder\" + 0.005*\"herring\" + 0.005*\"teeter\" + 0.005*\"fuckin\" + 0.004*\"didnt\" + 0.004*\"shin\" + 0.004*\"gonna\" + 0.004*\"did\"'),\n",
       " (3,\n",
       "  '0.015*\"saddle\" + 0.009*\"fckin\" + 0.007*\"mall\" + 0.007*\"fbi\" + 0.005*\"gonna\" + 0.005*\"shin\" + 0.005*\"gone\" + 0.005*\"come\" + 0.004*\"wallbuilder\" + 0.004*\"got\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These topics aren't looking too great. We've tried modifying our parameters. Let's try modifying our terms list as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #2 (Nouns Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One popular trick is to look only at terms that are from one part of speech (only nouns, only adjectives, etc.). Check out the UPenn tag set: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>Full_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adel_karam</th>\n",
       "      <td>a netflix comedy specialrecorded at the casino...</td>\n",
       "      <td>Adel Karam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amy_schumer</th>\n",
       "      <td>fuck yeah this is such a big night for you but...</td>\n",
       "      <td>Amy Schumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beth_stelling</th>\n",
       "      <td>beth stellings standup comedy special girl dad...</td>\n",
       "      <td>Beth Stelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_jay_oakerson</th>\n",
       "      <td>lets get you going here hey hey hey hey hey he...</td>\n",
       "      <td>Big Jay Oakerson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chelsea_handler</th>\n",
       "      <td>join me in welcoming the author of six number ...</td>\n",
       "      <td>Chris Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chris_rock</th>\n",
       "      <td>lets go she said ill do anything you want i sa...</td>\n",
       "      <td>Dave Chappelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave_chappelle</th>\n",
       "      <td>the dreamer which was shot in chappelles homet...</td>\n",
       "      <td>Chris Tucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>david_cross</th>\n",
       "      <td>david cross making america great again is a st...</td>\n",
       "      <td>Daniel Tosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dylan_moran</th>\n",
       "      <td>ladies and gentlemen will you please welcome t...</td>\n",
       "      <td>Dylan Moran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george_carlin</th>\n",
       "      <td>in the indian sergeant was emerging as george ...</td>\n",
       "      <td>George Carlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iliza_shlesinger</th>\n",
       "      <td>thank you nashville thank you so this year was...</td>\n",
       "      <td>Iliza Shlesinger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_hart</th>\n",
       "      <td>streaming on netflix from november yo whats up...</td>\n",
       "      <td>Kevin Hart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_james</th>\n",
       "      <td>kevin james irregardless in kevin james irrega...</td>\n",
       "      <td>Kevin James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis_c_k</th>\n",
       "      <td>louis louis alright lets get started go ahead ...</td>\n",
       "      <td>Louis C.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matt_rife</th>\n",
       "      <td>in his second hourlong comedy special matthew ...</td>\n",
       "      <td>Matt Rife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pete_davidson</th>\n",
       "      <td>pete davidson turbo fonzarelli released date j...</td>\n",
       "      <td>Pete Davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky_gervais</th>\n",
       "      <td>recorded before a live audience at the chicago...</td>\n",
       "      <td>Ricky Gervais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarah_cooper</th>\n",
       "      <td>this story is about sarah cooper who was a mor...</td>\n",
       "      <td>Sarah Cooper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom_segura</th>\n",
       "      <td>how you doing no shit thank you thank you how ...</td>\n",
       "      <td>Tom Segura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trevor_noah</th>\n",
       "      <td>detroit give it up for trevor noah whats going...</td>\n",
       "      <td>Trevor Noah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         transcript  \\\n",
       "adel_karam        a netflix comedy specialrecorded at the casino...   \n",
       "amy_schumer       fuck yeah this is such a big night for you but...   \n",
       "beth_stelling     beth stellings standup comedy special girl dad...   \n",
       "big_jay_oakerson  lets get you going here hey hey hey hey hey he...   \n",
       "chelsea_handler   join me in welcoming the author of six number ...   \n",
       "chris_rock        lets go she said ill do anything you want i sa...   \n",
       "dave_chappelle    the dreamer which was shot in chappelles homet...   \n",
       "david_cross       david cross making america great again is a st...   \n",
       "dylan_moran       ladies and gentlemen will you please welcome t...   \n",
       "george_carlin     in the indian sergeant was emerging as george ...   \n",
       "iliza_shlesinger  thank you nashville thank you so this year was...   \n",
       "kevin_hart        streaming on netflix from november yo whats up...   \n",
       "kevin_james       kevin james irregardless in kevin james irrega...   \n",
       "louis_c_k         louis louis alright lets get started go ahead ...   \n",
       "matt_rife         in his second hourlong comedy special matthew ...   \n",
       "pete_davidson     pete davidson turbo fonzarelli released date j...   \n",
       "ricky_gervais     recorded before a live audience at the chicago...   \n",
       "sarah_cooper      this story is about sarah cooper who was a mor...   \n",
       "tom_segura        how you doing no shit thank you thank you how ...   \n",
       "trevor_noah       detroit give it up for trevor noah whats going...   \n",
       "\n",
       "                         Full_Name  \n",
       "adel_karam              Adel Karam  \n",
       "amy_schumer            Amy Schumer  \n",
       "beth_stelling        Beth Stelling  \n",
       "big_jay_oakerson  Big Jay Oakerson  \n",
       "chelsea_handler         Chris Rock  \n",
       "chris_rock          Dave Chappelle  \n",
       "dave_chappelle        Chris Tucker  \n",
       "david_cross            Daniel Tosh  \n",
       "dylan_moran            Dylan Moran  \n",
       "george_carlin        George Carlin  \n",
       "iliza_shlesinger  Iliza Shlesinger  \n",
       "kevin_hart              Kevin Hart  \n",
       "kevin_james            Kevin James  \n",
       "louis_c_k               Louis C.K.  \n",
       "matt_rife                Matt Rife  \n",
       "pete_davidson        Pete Davidson  \n",
       "ricky_gervais        Ricky Gervais  \n",
       "sarah_cooper          Sarah Cooper  \n",
       "tom_segura              Tom Segura  \n",
       "trevor_noah            Trevor Noah  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adel_karam</th>\n",
       "      <td>comedy casino beirut hello wow evening evening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amy_schumer</th>\n",
       "      <td>fuck yeah night celebrating i highschool crush...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beth_stelling</th>\n",
       "      <td>stellings comedy girl daddy hbo max show varsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_jay_oakerson</th>\n",
       "      <td>lets hey hey hey hey hey lets wow lot bravado ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chelsea_handler</th>\n",
       "      <td>author number york times books star chelsea ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chris_rock</th>\n",
       "      <td>lets anything i bitch paint house death penalt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave_chappelle</th>\n",
       "      <td>dreamer chappelles hometown washington dc linc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>david_cross</th>\n",
       "      <td>cross making comedy comedian actor david cross...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dylan_moran</th>\n",
       "      <td>ladies gentlemen stage mr dylan hello thank th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george_carlin</th>\n",
       "      <td>sergeant george carlins premise warrior troops...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iliza_shlesinger</th>\n",
       "      <td>thank year year i i reciprocity i something po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_hart</th>\n",
       "      <td>netflix yo i house yall work homework look eye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_james</th>\n",
       "      <td>kevin james kevin james standup comedy kevin j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis_c_k</th>\n",
       "      <td>louis lets opening act lets seats beers everyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matt_rife</th>\n",
       "      <td>comedy matthew stephen rife rife performance n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pete_davidson</th>\n",
       "      <td>davidson turbo fonzarelli date netflixruntime ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky_gervais</th>\n",
       "      <td>audience chicago theatre music applause announ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarah_cooper</th>\n",
       "      <td>story cooper morning news anchor spring fall c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom_segura</th>\n",
       "      <td>shit thank thank texas um yeah i road i wife k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trevor_noah</th>\n",
       "      <td>trevor noah detroit everybody show thank look ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         transcript\n",
       "adel_karam        comedy casino beirut hello wow evening evening...\n",
       "amy_schumer       fuck yeah night celebrating i highschool crush...\n",
       "beth_stelling     stellings comedy girl daddy hbo max show varsi...\n",
       "big_jay_oakerson  lets hey hey hey hey hey lets wow lot bravado ...\n",
       "chelsea_handler   author number york times books star chelsea ch...\n",
       "chris_rock        lets anything i bitch paint house death penalt...\n",
       "dave_chappelle    dreamer chappelles hometown washington dc linc...\n",
       "david_cross       cross making comedy comedian actor david cross...\n",
       "dylan_moran       ladies gentlemen stage mr dylan hello thank th...\n",
       "george_carlin     sergeant george carlins premise warrior troops...\n",
       "iliza_shlesinger  thank year year i i reciprocity i something po...\n",
       "kevin_hart        netflix yo i house yall work homework look eye...\n",
       "kevin_james       kevin james kevin james standup comedy kevin j...\n",
       "louis_c_k         louis lets opening act lets seats beers everyb...\n",
       "matt_rife         comedy matthew stephen rife rife performance n...\n",
       "pete_davidson     davidson turbo fonzarelli date netflixruntime ...\n",
       "ricky_gervais     audience chicago theatre music applause announ...\n",
       "sarah_cooper      story cooper morning news anchor spring fall c...\n",
       "tom_segura        shit thank thank texas um yeah i road i wife k...\n",
       "trevor_noah       trevor noah detroit everybody show thank look ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aah</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbas</th>\n",
       "      <th>abduction</th>\n",
       "      <th>ability</th>\n",
       "      <th>abo</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortions</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absense</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zit</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adel_karam</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amy_schumer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beth_stelling</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_jay_oakerson</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chelsea_handler</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chris_rock</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave_chappelle</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>david_cross</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dylan_moran</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george_carlin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iliza_shlesinger</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_hart</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_james</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis_c_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matt_rife</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pete_davidson</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky_gervais</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarah_cooper</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom_segura</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trevor_noah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 6315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aah  ab  abbas  abduction  ability  abo  abortion  \\\n",
       "adel_karam          0   0      1          0        0    1         0   \n",
       "amy_schumer         1   0      0          0        0    0         0   \n",
       "beth_stelling       0   0      0          0        0    0         5   \n",
       "big_jay_oakerson    0   0      0          0        0    0         0   \n",
       "chelsea_handler     0   0      0          0        1    0         0   \n",
       "chris_rock          0   0      0          0        0    0         7   \n",
       "dave_chappelle      1   0      0          0        0    0         0   \n",
       "david_cross         0   0      0          0        0    0         0   \n",
       "dylan_moran         0   1      0          0        0    0         0   \n",
       "george_carlin       0   0      0          0        0    0         0   \n",
       "iliza_shlesinger    0   0      0          0        0    0         0   \n",
       "kevin_hart          1   0      0          0        0    0         0   \n",
       "kevin_james         0   0      0          0        0    0         0   \n",
       "louis_c_k           0   0      0          0        0    0         0   \n",
       "matt_rife           0   0      0          0        0    0         0   \n",
       "pete_davidson       1   0      0          0        1    0         0   \n",
       "ricky_gervais       0   0      0          1        0    0         0   \n",
       "sarah_cooper        0   0      0          0        0    0         0   \n",
       "tom_segura          0   0      0          0        0    0         0   \n",
       "trevor_noah         0   0      0          0        0    0         0   \n",
       "\n",
       "                  abortions  abraham  absense  ...  zero  zillion  zip  zit  \\\n",
       "adel_karam                0        0        0  ...     0        0    0    1   \n",
       "amy_schumer               0        0        0  ...     1        0    0    0   \n",
       "beth_stelling             0        0        0  ...     0        0    1    0   \n",
       "big_jay_oakerson          0        0        0  ...     1        1    0    0   \n",
       "chelsea_handler           0        0        0  ...     0        0    0    0   \n",
       "chris_rock                2        0        0  ...     0        0    0    0   \n",
       "dave_chappelle            0        0        0  ...     0        0    0    0   \n",
       "david_cross               0        0        0  ...     0        0    0    0   \n",
       "dylan_moran               0        0        0  ...     0        0    0    0   \n",
       "george_carlin             0        0        0  ...     0        0    0    0   \n",
       "iliza_shlesinger          0        0        0  ...     0        0    0    0   \n",
       "kevin_hart                0        0        0  ...     0        0    0    0   \n",
       "kevin_james               0        0        0  ...     0        0    0    0   \n",
       "louis_c_k                 0        1        1  ...     0        0    0    0   \n",
       "matt_rife                 0        0        0  ...     0        0    0    0   \n",
       "pete_davidson             0        0        0  ...     0        0    0    0   \n",
       "ricky_gervais             0        0        0  ...     0        0    0    0   \n",
       "sarah_cooper              0        0        0  ...     0        0    0    0   \n",
       "tom_segura                0        0        0  ...     0        0    0    0   \n",
       "trevor_noah               0        0        0  ...     0        0    0    0   \n",
       "\n",
       "                  zombie  zombies  zone  zoo  zoologist  zoom  \n",
       "adel_karam             0        0     0    0          0     0  \n",
       "amy_schumer            1        0     0    0          0     0  \n",
       "beth_stelling          0        0     0    0          0     0  \n",
       "big_jay_oakerson       0        0     0    0          0     0  \n",
       "chelsea_handler        0        0     0    0          0     0  \n",
       "chris_rock             0        0     0    1          0     0  \n",
       "dave_chappelle         0        0     0    0          0     0  \n",
       "david_cross            0        0     0    0          0     0  \n",
       "dylan_moran            1        0     0    0          0     0  \n",
       "george_carlin          0        0     0    0          0     0  \n",
       "iliza_shlesinger       1        0     0    0          0     0  \n",
       "kevin_hart             0        1     1    0          0     0  \n",
       "kevin_james            0        0     0    0          0     0  \n",
       "louis_c_k              0        0     0    0          0     0  \n",
       "matt_rife              0        0     1    0          0     0  \n",
       "pete_davidson          0        0     1    0          0     1  \n",
       "ricky_gervais          0        0     0    0          1     0  \n",
       "sarah_cooper           0        0     0    1          0     1  \n",
       "tom_segura             0        0     0    0          0     0  \n",
       "trevor_noah            0        0     0    0          0     0  \n",
       "\n",
       "[20 rows x 6315 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said', \n",
    "                  'get', 'going', 'want', 'make', 'way', 'good', 'thing', 'need', \n",
    "                  'lot', 'really', 'come', 'look', 'use', 'said']\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(add_stop_words))\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"man\" + 0.008*\"hes\" + 0.006*\"day\" + 0.006*\"gon\" + 0.006*\"things\" + 0.006*\"theyre\" + 0.006*\"life\" + 0.006*\"kids\" + 0.005*\"cause\" + 0.005*\"years\"'),\n",
       " (1,\n",
       "  '0.012*\"man\" + 0.009*\"shes\" + 0.008*\"life\" + 0.008*\"guy\" + 0.007*\"cause\" + 0.007*\"hes\" + 0.007*\"shit\" + 0.006*\"day\" + 0.006*\"everybody\" + 0.006*\"fuck\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"man\" + 0.008*\"guy\" + 0.008*\"shes\" + 0.008*\"shit\" + 0.008*\"hes\" + 0.007*\"kids\" + 0.006*\"gon\" + 0.006*\"cause\" + 0.006*\"life\" + 0.006*\"day\"'),\n",
       " (1,\n",
       "  '0.009*\"hes\" + 0.007*\"okay\" + 0.007*\"theyre\" + 0.006*\"cause\" + 0.006*\"day\" + 0.005*\"god\" + 0.005*\"gon\" + 0.005*\"shes\" + 0.005*\"man\" + 0.005*\"women\"'),\n",
       " (2,\n",
       "  '0.016*\"man\" + 0.009*\"life\" + 0.008*\"everybody\" + 0.008*\"day\" + 0.007*\"hes\" + 0.006*\"things\" + 0.006*\"shit\" + 0.006*\"cause\" + 0.006*\"world\" + 0.006*\"gon\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"hes\" + 0.007*\"theyre\" + 0.007*\"god\" + 0.006*\"day\" + 0.006*\"cause\" + 0.005*\"gon\" + 0.005*\"okay\" + 0.005*\"kids\" + 0.005*\"life\" + 0.005*\"bit\"'),\n",
       " (1,\n",
       "  '0.010*\"mom\" + 0.006*\"shes\" + 0.006*\"hes\" + 0.006*\"sarah\" + 0.005*\"cause\" + 0.005*\"house\" + 0.005*\"okay\" + 0.004*\"life\" + 0.004*\"years\" + 0.004*\"cooper\"'),\n",
       " (2,\n",
       "  '0.015*\"man\" + 0.009*\"gon\" + 0.008*\"day\" + 0.008*\"hes\" + 0.007*\"life\" + 0.007*\"dick\" + 0.007*\"shes\" + 0.007*\"things\" + 0.007*\"shit\" + 0.007*\"guy\"'),\n",
       " (3,\n",
       "  '0.013*\"man\" + 0.009*\"shit\" + 0.008*\"life\" + 0.008*\"hes\" + 0.008*\"guy\" + 0.007*\"everybody\" + 0.007*\"kids\" + 0.007*\"theyre\" + 0.007*\"women\" + 0.007*\"shes\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adel_karam</th>\n",
       "      <td>netflix comedy casino du liban beirut hello wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amy_schumer</th>\n",
       "      <td>fuck yeah big night celebrating i highschool c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beth_stelling</th>\n",
       "      <td>beth stellings comedy special girl daddy hbo m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_jay_oakerson</th>\n",
       "      <td>lets hey hey hey hey hey lets wow lot bravado ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chelsea_handler</th>\n",
       "      <td>author number new york times books star chelse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chris_rock</th>\n",
       "      <td>lets ill anything i bitch paint house death pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave_chappelle</th>\n",
       "      <td>dreamer chappelles hometown washington dc linc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>david_cross</th>\n",
       "      <td>david cross making great standup comedy specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dylan_moran</th>\n",
       "      <td>ladies gentlemen stage mr dylan hey hello than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george_carlin</th>\n",
       "      <td>indian sergeant george carlins premise indian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iliza_shlesinger</th>\n",
       "      <td>thank year important year i i reciprocity i so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_hart</th>\n",
       "      <td>netflix november yo i house yall work champ ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_james</th>\n",
       "      <td>kevin james kevin james standup comedy special...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis_c_k</th>\n",
       "      <td>louis alright lets okay opening act start lets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matt_rife</th>\n",
       "      <td>second hourlong comedy special matthew stephen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pete_davidson</th>\n",
       "      <td>pete davidson turbo fonzarelli date january ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky_gervais</th>\n",
       "      <td>live audience chicago theatre chicago music ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarah_cooper</th>\n",
       "      <td>story sarah cooper morning news anchor spring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom_segura</th>\n",
       "      <td>shit thank right thank great austin texas um y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trevor_noah</th>\n",
       "      <td>trevor noah detroit tonight everybody welcome ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         transcript\n",
       "adel_karam        netflix comedy casino du liban beirut hello wo...\n",
       "amy_schumer       fuck yeah big night celebrating i highschool c...\n",
       "beth_stelling     beth stellings comedy special girl daddy hbo m...\n",
       "big_jay_oakerson  lets hey hey hey hey hey lets wow lot bravado ...\n",
       "chelsea_handler   author number new york times books star chelse...\n",
       "chris_rock        lets ill anything i bitch paint house death pe...\n",
       "dave_chappelle    dreamer chappelles hometown washington dc linc...\n",
       "david_cross       david cross making great standup comedy specia...\n",
       "dylan_moran       ladies gentlemen stage mr dylan hey hello than...\n",
       "george_carlin     indian sergeant george carlins premise indian ...\n",
       "iliza_shlesinger  thank year important year i i reciprocity i so...\n",
       "kevin_hart        netflix november yo i house yall work champ ho...\n",
       "kevin_james       kevin james kevin james standup comedy special...\n",
       "louis_c_k         louis alright lets okay opening act start lets...\n",
       "matt_rife         second hourlong comedy special matthew stephen...\n",
       "pete_davidson     pete davidson turbo fonzarelli date january ne...\n",
       "ricky_gervais     live audience chicago theatre chicago music ap...\n",
       "sarah_cooper      story sarah cooper morning news anchor spring ...\n",
       "tom_segura        shit thank right thank great austin texas um y...\n",
       "trevor_noah       trevor noah detroit tonight everybody welcome ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aah</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbas</th>\n",
       "      <th>abduction</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abo</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortions</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zit</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adel_karam</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amy_schumer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beth_stelling</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_jay_oakerson</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chelsea_handler</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chris_rock</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dave_chappelle</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>david_cross</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dylan_moran</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>george_carlin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iliza_shlesinger</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_hart</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin_james</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis_c_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matt_rife</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pete_davidson</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricky_gervais</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarah_cooper</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tom_segura</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trevor_noah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 7661 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aah  ab  abandoned  abbas  abduction  ability  able  abo  \\\n",
       "adel_karam          0   0          0      2          0        0     0   10   \n",
       "amy_schumer         1   0          0      0          0        0     1    0   \n",
       "beth_stelling       0   0          0      0          0        0     1    0   \n",
       "big_jay_oakerson    0   0          2      0          0        0     0    0   \n",
       "chelsea_handler     0   0          0      0          0        1     5    0   \n",
       "chris_rock          0   0          0      0          0        0     2    0   \n",
       "dave_chappelle      1   0          0      0          0        0     0    0   \n",
       "david_cross         0   0          0      0          0        0     6    0   \n",
       "dylan_moran         0   1          0      0          0        0     4    0   \n",
       "george_carlin       0   0          0      0          0        0     0    0   \n",
       "iliza_shlesinger    0   0          0      0          0        0     0    0   \n",
       "kevin_hart          2   0          0      0          0        0     2    0   \n",
       "kevin_james         0   0          0      0          0        0     0    0   \n",
       "louis_c_k           0   0          0      0          0        0     1    0   \n",
       "matt_rife           0   0          0      0          0        0     3    0   \n",
       "pete_davidson       1   0          0      0          0        1     1    0   \n",
       "ricky_gervais       0   0          0      0          1        0     1    0   \n",
       "sarah_cooper        0   0          0      0          0        0     3    0   \n",
       "tom_segura          0   0          0      0          0        0     1    0   \n",
       "trevor_noah         0   0          0      0          0        0     1    0   \n",
       "\n",
       "                  abortion  abortions  ...  zero  zillion  zip  zit  zombie  \\\n",
       "adel_karam               0          0  ...     0        0    0    1       0   \n",
       "amy_schumer              0          0  ...     1        0    0    0       1   \n",
       "beth_stelling            5          0  ...     0        0    1    0       0   \n",
       "big_jay_oakerson         0          0  ...     1        1    0    0       0   \n",
       "chelsea_handler          0          0  ...     0        0    0    0       0   \n",
       "chris_rock               7          2  ...     0        0    0    0       0   \n",
       "dave_chappelle           0          0  ...     0        0    0    0       0   \n",
       "david_cross              0          0  ...     0        0    0    0       0   \n",
       "dylan_moran              0          0  ...     0        0    0    0       1   \n",
       "george_carlin            0          0  ...     0        0    0    0       0   \n",
       "iliza_shlesinger         0          0  ...     0        0    0    0       1   \n",
       "kevin_hart               0          0  ...     0        0    0    0       0   \n",
       "kevin_james              0          0  ...     0        0    0    0       0   \n",
       "louis_c_k                0          0  ...     0        0    0    0       0   \n",
       "matt_rife                0          0  ...     0        0    0    0       0   \n",
       "pete_davidson            0          0  ...     0        0    0    0       0   \n",
       "ricky_gervais            0          0  ...     0        0    0    0       0   \n",
       "sarah_cooper             0          0  ...     0        0    0    0       0   \n",
       "tom_segura               0          0  ...     0        0    0    0       0   \n",
       "trevor_noah              0          0  ...     0        0    0    0       0   \n",
       "\n",
       "                  zombies  zone  zoo  zoologist  zoom  \n",
       "adel_karam              0     0    0          0     0  \n",
       "amy_schumer             0     0    0          0     0  \n",
       "beth_stelling           0     0    0          0     0  \n",
       "big_jay_oakerson        0     0    0          0     0  \n",
       "chelsea_handler         0     0    0          0     0  \n",
       "chris_rock              0     0    1          0     0  \n",
       "dave_chappelle          0     0    0          0     0  \n",
       "david_cross             0     0    0          0     0  \n",
       "dylan_moran             0     0    0          0     0  \n",
       "george_carlin           0     0    0          0     0  \n",
       "iliza_shlesinger        0     0    0          0     0  \n",
       "kevin_hart              1     1    0          0     0  \n",
       "kevin_james             0     0    0          0     0  \n",
       "louis_c_k               0     0    0          0     0  \n",
       "matt_rife               0     1    0          0     0  \n",
       "pete_davidson           0     1    0          0     1  \n",
       "ricky_gervais           0     0    0          1     0  \n",
       "sarah_cooper            0     0    1          0     1  \n",
       "tom_segura              0     0    0          0     0  \n",
       "trevor_noah             0     0    0          0     0  \n",
       "\n",
       "[20 rows x 7661 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"women\" + 0.004*\"mom\" + 0.004*\"fuck\" + 0.003*\"men\" + 0.003*\"fat\" + 0.003*\"ta\" + 0.003*\"fucking\" + 0.003*\"somebody\" + 0.003*\"girls\" + 0.003*\"fun\"'),\n",
       " (1,\n",
       "  '0.006*\"dick\" + 0.005*\"black\" + 0.005*\"fuck\" + 0.004*\"house\" + 0.004*\"fck\" + 0.003*\"women\" + 0.003*\"ta\" + 0.003*\"ass\" + 0.003*\"men\" + 0.003*\"school\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"ta\" + 0.004*\"women\" + 0.004*\"fuck\" + 0.004*\"fck\" + 0.004*\"men\" + 0.003*\"fat\" + 0.003*\"house\" + 0.003*\"wife\" + 0.003*\"kid\" + 0.003*\"stuff\"'),\n",
       " (1,\n",
       "  '0.008*\"fuck\" + 0.007*\"mom\" + 0.007*\"dick\" + 0.006*\"black\" + 0.004*\"women\" + 0.004*\"girls\" + 0.004*\"fucking\" + 0.004*\"dude\" + 0.003*\"ass\" + 0.003*\"pussy\"'),\n",
       " (2,\n",
       "  '0.005*\"sarah\" + 0.004*\"anthem\" + 0.004*\"nice\" + 0.004*\"cooper\" + 0.004*\"morning\" + 0.003*\"women\" + 0.003*\"news\" + 0.003*\"somebody\" + 0.003*\"sex\" + 0.003*\"america\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"fuck\" + 0.007*\"women\" + 0.005*\"dick\" + 0.004*\"black\" + 0.004*\"men\" + 0.004*\"somebody\" + 0.004*\"fucking\" + 0.004*\"fun\" + 0.004*\"girls\" + 0.003*\"mom\"'),\n",
       " (1,\n",
       "  '0.008*\"anthem\" + 0.005*\"song\" + 0.005*\"germany\" + 0.005*\"america\" + 0.005*\"french\" + 0.004*\"bathroom\" + 0.004*\"girls\" + 0.004*\"number\" + 0.004*\"national\" + 0.004*\"country\"'),\n",
       " (2,\n",
       "  '0.005*\"sarah\" + 0.004*\"morning\" + 0.004*\"nice\" + 0.004*\"cooper\" + 0.003*\"ta\" + 0.003*\"water\" + 0.003*\"dani\" + 0.003*\"news\" + 0.003*\"everythings\" + 0.003*\"hell\"'),\n",
       " (3,\n",
       "  '0.009*\"fck\" + 0.007*\"house\" + 0.007*\"mom\" + 0.006*\"fcking\" + 0.005*\"fat\" + 0.005*\"ta\" + 0.005*\"fuck\" + 0.004*\"ass\" + 0.004*\"dick\" + 0.003*\"gay\"')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Topics in Each Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 9 topic models we looked at, the nouns and adjectives, 4 topic one made the most sense. So let's pull that down here and run it through some more iterations to get more fine-tuned topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"fck\" + 0.006*\"fcking\" + 0.005*\"anthem\" + 0.004*\"mom\" + 0.004*\"house\" + 0.004*\"sex\" + 0.004*\"somebody\" + 0.004*\"ass\" + 0.004*\"ta\" + 0.004*\"dick\"'),\n",
       " (1,\n",
       "  '0.007*\"fuck\" + 0.007*\"black\" + 0.005*\"ass\" + 0.005*\"women\" + 0.005*\"dani\" + 0.005*\"class\" + 0.005*\"school\" + 0.004*\"ngga\" + 0.004*\"men\" + 0.004*\"shoes\"'),\n",
       " (2,\n",
       "  '0.007*\"fat\" + 0.005*\"ta\" + 0.004*\"game\" + 0.003*\"gay\" + 0.003*\"book\" + 0.003*\"men\" + 0.003*\"natural\" + 0.003*\"earth\" + 0.003*\"ready\" + 0.003*\"plane\"'),\n",
       " (3,\n",
       "  '0.006*\"fuck\" + 0.005*\"women\" + 0.005*\"dick\" + 0.005*\"mom\" + 0.004*\"fucking\" + 0.003*\"fun\" + 0.003*\"somebody\" + 0.003*\"girls\" + 0.003*\"nice\" + 0.003*\"house\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To divide the comedian transcript into four topics based on the provided topic keywords, we can infer some general themes for each topic:\n",
    "\n",
    "* Topic 0: Sex and Vulgarity\n",
    "Keywords: \"fuck\", \"fucking\", \"ass\", \"dick\", \"sex\"\n",
    "This topic seems to focus on explicit language and sexual content.\n",
    "\n",
    "* Topic 1: Race and Gender\n",
    "Keywords: \"black\", \"women\", \"class\", \"school\", \"ngga\"\n",
    "This topic appears to revolve around issues related to race, gender, and societal stereotypes.\n",
    "\n",
    "* Topic 2: Body Image and Identity\n",
    "Keywords: \"fat\", \"gay\", \"natural\", \"earth\"\n",
    "This topic seems to discuss themes related to body image, sexuality, and perhaps identity.\n",
    "\n",
    "* Topic 3: Relationships and Social Interactions\n",
    "Keywords: \"mom\", \"women\", \"dick\", \"girls\", \"house\"\n",
    "This topic might involve discussions about relationships, family dynamics, and social interactions.\n",
    "\n",
    "These are broad interpretations based on the provided keywords. Depending on the context of the comedian's routine, the actual topics could be more nuanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'adel_karam'),\n",
       " (0, 'amy_schumer'),\n",
       " (0, 'beth_stelling'),\n",
       " (3, 'big_jay_oakerson'),\n",
       " (3, 'chelsea_handler'),\n",
       " (1, 'chris_rock'),\n",
       " (3, 'dave_chappelle'),\n",
       " (3, 'david_cross'),\n",
       " (3, 'dylan_moran'),\n",
       " (1, 'george_carlin'),\n",
       " (3, 'iliza_shlesinger'),\n",
       " (0, 'kevin_hart'),\n",
       " (2, 'kevin_james'),\n",
       " (3, 'louis_c_k'),\n",
       " (3, 'matt_rife'),\n",
       " (3, 'pete_davidson'),\n",
       " (2, 'ricky_gervais'),\n",
       " (3, 'sarah_cooper'),\n",
       " (3, 'tom_segura'),\n",
       " (0, 'trevor_noah')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on the provided comedian names and their associated topic numbers, here's how they are divided into the four topics:\n",
    "\n",
    "Topic 0: Sex and Vulgarity\n",
    "- Amy Schumer\n",
    "- Beth Stelling\n",
    "- Kevin Hart\n",
    "- Trevor Noah\n",
    "\n",
    "Topic 1: Race and Gender\n",
    "- Adel Karam\n",
    "- Chris Rock\n",
    "- George Carlin\n",
    "\n",
    "Topic 2: Body Image and Identity\n",
    "- Kevin James\n",
    "- Ricky Gervais\n",
    "\n",
    "Topic 3: Relationships and Social Interactions\n",
    "- Big Jay Oakerson\n",
    "- Chelsea Handler\n",
    "- Dave Chappelle\n",
    "- David Cross\n",
    "- Dylan Moran\n",
    "- Iliza Shlesinger\n",
    "- Louis C.K.\n",
    "- Matt Rife\n",
    "- Pete Davidson\n",
    "- Sarah Cooper\n",
    "- Tom Segura\n",
    "\n",
    "These categorizations are based on the topics inferred from the provided keywords and may not perfectly align with the content or style of each comedian's routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment:\n",
    "1. Try further modifying the parameters of the topic models above and see if you can get better topics.\n",
    "2. Create a new topic model that includes terms from a different [part of speech](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) and see if you can get better topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"fck\" + 0.007*\"fcking\" + 0.006*\"fat\" + 0.005*\"ta\" + 0.005*\"house\" + 0.005*\"wife\" + 0.005*\"ngga\" + 0.004*\"fuck\" + 0.004*\"ass\" + 0.004*\"jokes\"'),\n",
       " (1,\n",
       "  '0.010*\"dick\" + 0.007*\"sarah\" + 0.005*\"nice\" + 0.005*\"black\" + 0.005*\"cooper\" + 0.004*\"dude\" + 0.004*\"hi\" + 0.004*\"girls\" + 0.004*\"president\" + 0.004*\"cool\"'),\n",
       " (2,\n",
       "  '0.009*\"anthem\" + 0.006*\"dani\" + 0.006*\"germany\" + 0.005*\"america\" + 0.005*\"song\" + 0.005*\"number\" + 0.005*\"class\" + 0.004*\"national\" + 0.004*\"country\" + 0.004*\"public\"'),\n",
       " (3,\n",
       "  '0.012*\"mom\" + 0.006*\"ta\" + 0.005*\"house\" + 0.005*\"fuck\" + 0.004*\"game\" + 0.004*\"stalker\" + 0.004*\"uh\" + 0.003*\"dad\" + 0.003*\"belt\" + 0.003*\"kid\"'),\n",
       " (4,\n",
       "  '0.000*\"fuck\" + 0.000*\"mom\" + 0.000*\"natural\" + 0.000*\"men\" + 0.000*\"ass\" + 0.000*\"village\" + 0.000*\"ones\" + 0.000*\"house\" + 0.000*\"girls\" + 0.000*\"easy\"'),\n",
       " (5,\n",
       "  '0.008*\"women\" + 0.007*\"fuck\" + 0.005*\"men\" + 0.005*\"somebody\" + 0.004*\"girls\" + 0.004*\"black\" + 0.004*\"mom\" + 0.004*\"fucking\" + 0.004*\"fun\" + 0.003*\"dog\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=6, id2word=id2wordna, passes=100)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To divide the comedian transcript into six topics based on the provided topic keywords, we can infer the following themes for each topic:\n",
    "\n",
    "Topic 0: Vulgarity and Relationships\n",
    "- Keywords: \"fuck\", \"fucking\", \"ass\", \"dick\", \"wife\", \"jokes\"\n",
    "- This topic appears to involve vulgar language and jokes related to relationships.\n",
    "\n",
    "Topic 1: Social Interactions and Politics\n",
    "- Keywords: \"sarah\", \"cooper\", \"president\", \"girls\", \"cool\"\n",
    "- This topic seems to discuss social interactions, politics, and possibly gender-related issues.\n",
    "\n",
    "Topic 2: National Identity and Patriotism\n",
    "- Keywords: \"anthem\", \"germany\", \"america\", \"song\", \"national\", \"country\"\n",
    "- This topic may involve discussions about national identity, anthems, and patriotism.\n",
    "\n",
    "Topic 3: Family and Childhood\n",
    "- Keywords: \"mom\", \"house\", \"game\", \"stalker\", \"dad\", \"kid\"\n",
    "- This topic likely covers themes related to family dynamics, childhood experiences, and perhaps darker humor.\n",
    "\n",
    "Topic 4: Unclear or Irrelevant Keywords\n",
    "- Keywords: \"natural\", \"men\", \"village\", \"ones\", \"house\", \"girls\", \"easy\"\n",
    "- This topic doesn't seem to have clear or relevant keywords to determine its theme.\n",
    "\n",
    "Topic 5: Gender and Relationships\n",
    "- Keywords: \"women\", \"fuck\", \"men\", \"somebody\", \"girls\", \"mom\", \"fucking\", \"fun\"\n",
    "- This topic could involve discussions about gender dynamics, relationships, and possibly sexual content.\n",
    "\n",
    "These are broad interpretations based on the provided keywords. Depending on the context of the comedian's routine, the actual topics could be more nuanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'adel_karam'),\n",
       " (5, 'amy_schumer'),\n",
       " (5, 'beth_stelling'),\n",
       " (1, 'big_jay_oakerson'),\n",
       " (5, 'chelsea_handler'),\n",
       " (5, 'chris_rock'),\n",
       " (0, 'dave_chappelle'),\n",
       " (1, 'david_cross'),\n",
       " (5, 'dylan_moran'),\n",
       " (2, 'george_carlin'),\n",
       " (5, 'iliza_shlesinger'),\n",
       " (0, 'kevin_hart'),\n",
       " (3, 'kevin_james'),\n",
       " (5, 'louis_c_k'),\n",
       " (5, 'matt_rife'),\n",
       " (3, 'pete_davidson'),\n",
       " (0, 'ricky_gervais'),\n",
       " (1, 'sarah_cooper'),\n",
       " (5, 'tom_segura'),\n",
       " (2, 'trevor_noah')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "To create a new topic model that includes terms from a different part of speech, you can modify the text preprocessing step to filter for different parts of speech. For example, you can focus on verbs, adjectives, or adverbs instead of nouns and adjectives. Here's how you can modify the code to include terms from a different part of speech (verbs in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter for verbs in a string of text\n",
    "def verbs(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the verbs.'''\n",
    "    is_verb = lambda pos: pos[:2] == 'VB'  # VB: Verb, base form\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_verbs = [word for (word, pos) in pos_tag(tokenized) if is_verb(pos)] \n",
    "    return ' '.join(all_verbs)\n",
    "\n",
    "# Apply the verbs function to the transcripts to filter only on verbs\n",
    "data_verbs = pd.DataFrame(data_clean.transcript.apply(verbs))\n",
    "\n",
    "# Recreate a document-term matrix using only verbs\n",
    "cvv = CountVectorizer(stop_words=stop_words)\n",
    "data_cvv = cvv.fit_transform(data_verbs.transcript)\n",
    "data_dtmv = pd.DataFrame(data_cvv.toarray(), columns=cvv.get_feature_names_out())\n",
    "data_dtmv.index = data_verbs.index\n",
    "\n",
    "# Create the gensim corpus\n",
    "corpusv = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmv.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordv = dict((v, k) for k, v in cvv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.024*\"goes\" + 0.016*\"did\" + 0.014*\"say\" + 0.014*\"fucking\" + 0.011*\"doing\" + 0.011*\"tell\" + 0.010*\"mean\" + 0.010*\"guys\" + 0.009*\"gon\" + 0.009*\"feel\"'),\n",
       " (1,\n",
       "  '0.016*\"did\" + 0.015*\"say\" + 0.011*\"went\" + 0.011*\"goes\" + 0.011*\"doing\" + 0.010*\"didnt\" + 0.010*\"tell\" + 0.009*\"came\" + 0.008*\"theres\" + 0.008*\"mean\"'),\n",
       " (2,\n",
       "  '0.015*\"love\" + 0.014*\"say\" + 0.012*\"did\" + 0.010*\"doing\" + 0.010*\"fucking\" + 0.009*\"gon\" + 0.008*\"trying\" + 0.008*\"tell\" + 0.007*\"getting\" + 0.007*\"went\"'),\n",
       " (3,\n",
       "  '0.017*\"tell\" + 0.013*\"say\" + 0.012*\"did\" + 0.010*\"didnt\" + 0.008*\"theres\" + 0.008*\"gon\" + 0.008*\"doing\" + 0.008*\"hes\" + 0.008*\"went\" + 0.007*\"love\"')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldav = models.LdaModel(corpus=corpusv, num_topics=4, id2word=id2wordv, passes=10)\n",
    "ldav.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To divide the comedian transcript into four topics based on the provided topic keywords, we can infer the following themes for each topic:\n",
    "\n",
    "Topic 0: Commentary and Expression\n",
    "- Keywords: \"goes\", \"say\", \"fucking\", \"doing\", \"tell\", \"guys\", \"mean\", \"feel\"\n",
    "- This topic appears to involve commentary, expressions, and perhaps the comedian's observations on various subjects.\n",
    "\n",
    "Topic 1: Narrative and Action\n",
    "- Keywords: \"did\", \"say\", \"went\", \"doing\", \"didnt\", \"tell\", \"came\", \"theres\", \"mean\"\n",
    "- This topic might focus on narratives, actions, and descriptions of events or situations.\n",
    "\n",
    "Topic 2: Emotion and Effort\n",
    "- Keywords: \"love\", \"say\", \"did\", \"doing\", \"fucking\", \"gon\", \"trying\", \"tell\", \"getting\", \"went\"\n",
    "- This topic could involve discussions about emotions, efforts, and the comedian's experiences.\n",
    "\n",
    "Topic 3: Statements and Reactions\n",
    "- Keywords: \"tell\", \"say\", \"did\", \"didnt\", \"theres\", \"gon\", \"doing\", \"hes\", \"went\", \"love\"\n",
    "- This topic may revolve around statements, reactions, and the comedian's responses to various scenarios.\n",
    "\n",
    "These are broad interpretations based on the provided keywords. Depending on the context of the comedian's routine, the actual topics could be more nuanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ldav' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Let's take a look at which topics each transcript contains\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m corpus_transformed \u001b[38;5;241m=\u001b[39m ldav[corpusna]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m([a \u001b[38;5;28;01mfor\u001b[39;00m [(a,b)] \u001b[38;5;129;01min\u001b[39;00m corpus_transformed], data_dtmna\u001b[38;5;241m.\u001b[39mindex))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ldav' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldav[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
